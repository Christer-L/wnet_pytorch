{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bded03d6",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "SIGMA_X2 = 4\n",
    "SIGMA_I2 = 10\n",
    "RADIUS = 5\n",
    "N_CLASSES = 1\n",
    "\n",
    "region_size = 2*[2*RADIUS+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e9aff14",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "def get_weights_tensor(image, d, regions_mold):\n",
    "\n",
    "    # Create a region matrix (height, width) for each pixel in the input image I and stack them into a tensor.\n",
    "    # Each pixel in the image corresponds to a single matrix with given pixel in the center.\n",
    "    # Tensor shape: (1, # of pixels in I, R_height, R_width)\n",
    "    regions = torch.nn.Unflatten(1, REGION_SIZE)(torch.nn.Unfold(REGION_SIZE, padding=RADIUS)(\n",
    "        image[(None,) * 2])).permute(0, 3, 1, 2)\n",
    "\n",
    "    i_f = image.flatten()\n",
    "    i_f = torch.unsqueeze(i_f, dim=1)\n",
    "    i_f = torch.unsqueeze(i_f, dim=1)\n",
    "    i_f = torch.unsqueeze(i_f, dim=0)\n",
    "    d = torch.unsqueeze(d, dim=0)\n",
    "    return torch.squeeze(((torch.exp(-torch.pow((regions - i_f), 2) / SIGMA_I2) * d) * regions_mold), dim=0)\n",
    "\n",
    "def get_distance_sq(p1, p2):\n",
    "    dif = p1 - p2\n",
    "    return np.dot(dif.T, dif)\n",
    "\n",
    "def generate_distance_tensor(r):\n",
    "    region = torch.zeros((2*r+1, 2*r+1))\n",
    "    for x in range(region.shape[0]):\n",
    "        for y in range(region.shape[1]):\n",
    "            region[x,y] = -get_distance_sq(np.array([x,y]), np.array([r,r]))\n",
    "    return torch.exp(torch.unsqueeze(region, dim=0)/SIGMA_X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544f6ef6",
   "metadata": {},
   "source": "### Weight tensor generation"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e7d99e4",
   "metadata": {
    "scrolled": true,
    "trusted": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 6254/6254 [57:47<00:00,  1.80it/s]  \n"
    }
   ],
   "source": "d = generate_distance_tensor(RADIUS)\nmold = torch.ones(256, 256)\nunfold = torch.nn.Unfold(region_size, padding=RADIUS)\nunflatten = torch.nn.Unflatten(1, region_size)\nregions_mold = unflatten(unfold(mold[(None,)*2])).permute(0,3,1,2)\n\nwith tqdm(total=len(glob(r\"C:\\Users\\clohk\\Desktop\\Projects\\WNet\\wnet_pytorch\\patches_tries\\*\"))) as pbar:\n    for patch_path in glob(r\"C:\\Users\\clohk\\Desktop\\Projects\\WNet\\wnet_pytorch\\patches_tries\\*\"):\n        filename = os.path.basename(os.path.splitext(os.path.normpath(patch_path))[0])\n        img = np.array(Image.open(patch_path))\n        img = cv2.resize(img, (256, 256), interpolation = cv2.INTER_AREA)\n        torch.save(get_weights_tensor(torch.Tensor(img), d, regions_mold), r\"C:\\Users\\clohk\\Desktop\\Projects\\WNet\\wnet_pytorch\\weights\\{}.pt\".format(filename))\n        pbar.update(1)"
  },
  {
   "cell_type": "markdown",
   "source": "### Loss function",
   "metadata": {
    "collapsed": false
   },
   "id": "0d9636a4"
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": "unfold = torch.nn.Unfold(region_size, padding=RADIUS)\nunflatten = torch.nn.Unflatten(1, region_size)\nimage = torch.Tensor(img)\nCLASS_PROBABILITIES = torch.rand_like(image)\n",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "id": "877c71a6"
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.4934)"
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": "W = torch.load(r\"C:\\Users\\clohk\\Desktop\\Projects\\WNet\\wnet_pytorch\\weights\\180_s10_10_2.pt\")\nP = torch.squeeze(unflatten(unfold(CLASS_PROBABILITIES[(None,)*2])).permute(0,3,1,2), dim=0)\nL = 1 - torch.matmul(CLASS_PROBABILITIES.flatten(), torch.sum(W * P, dim=(1,2)))/ \\\n        torch.matmul(CLASS_PROBABILITIES.flatten(), torch.sum(W, dim=(1,2)))\nL",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "id": "bd2afd0d"
  },
  {
   "cell_type": "markdown",
   "source": "### Testing",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "3b04c9aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": "d = generate_distance_tensor(RADIUS)\nmold = torch.ones(256, 256)\nunfold = torch.nn.Unfold(region_size, padding=RADIUS)\nunflatten = torch.nn.Unflatten(1, region_size)\nregions_mold = unflatten(unfold(mold[(None,)*2])).permute(0,3,1,2)",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": false
   },
   "id": "bc65d9e8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}